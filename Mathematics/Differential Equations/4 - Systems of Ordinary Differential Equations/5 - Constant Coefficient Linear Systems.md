There are very few systems of ODEs that we can write the complete analytical solution for. One important instance when we can is when the coefficient matrix $\mathbf A$ is comprised of only constants. In this case, we can use basic linear algebra to find many, if not all the solutions.

Suppose that $\mathbf A$ has a set of eigenvectors $\{\mathbf u_k\}$ with corresponding eigenvalues $\lambda_k$, then the functions $\mathbf v_k(t)=\mathbf u_ke^{\lambda_kt}$. are solutions to the constant coefficient linear homogeneous system. If the eigenvalues are distinct then the solutions are linearly independent.

Matrices don't always have a complete set of eigenvectors, but the annihilator method doesn't apply for systems, so we need to find an alternate way to directly compute the fundamental solution matrix.

For a constant coefficient homogeneous linear differential equation, define the **matrix exponential** $\mathbf M(t)=e^{\mathbf At}$ to be the fundamental solution matrix satisfying the initial condition $\mathbf M(0)=\mathbf I$. It can alternatively be defined by the power series $$e^{\mathbf At}=\mathbf I+\mathbf At+\frac{\mathbf A^2t^2}{2!}+\ldots=\mathbf I+\sum_{k=1}^{\infty}\frac{t^k\mathbf A^k}{k!}$$It's usually not practical to directly compute the matrix exponential, but possible for simple cases. There are two main methods for computing the matrix exponential: **diagonalization** and **Putzer's method**.

Suppose that the coefficient matrix has $n$ linearly independent eigenvectors. Then let $\mathbf U$ denote the matrix with columns given by the eigenvectors, and $\mathbf U^{-1}$ denote the inverse (which must exist as the eigenvectors are assumed linearly independent), then the matrix exponential is given by $$e^{\mathbf At}=\mathbf U\begin{pmatrix}e^{\lambda_1t} & 0 & \ldots & 0 \\ 0 & e^{\lambda_2t}& \ldots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \ldots & e^{\lambda_nt}\end{pmatrix}\mathbf U^{-1}$$
The Putzer method defines the matrix family $\mathbf B_k=\prod_{i=1}^{k}(\mathbf A-\lambda_i\mathbf I)$ for $k\leq n-1$ and $\mathbf B_0=\mathbf I$, and a sequence of functions $r_k'=\lambda_kr_k+r_{k-1}, r_k(0)=0$ for $k\leq n$ and $r_1=\lambda_1r_1, r_1(0)=1$. Then, the matrix exponential is given by $$e^{\mathbf At}=r_1(t)\mathbf B_0+r_2(t)\mathbf B_1+\ldots+r_n(t)\mathbf B_{n-1}=\sum_{k=0}^{n-1}r_{k=0}(t)\mathbf B_k$$While the Putzer method is more computations, they're all much easier than the calculation of eigenvectors and inversion of a matrix necessary for the diagonalization method, and it works for all matrices.