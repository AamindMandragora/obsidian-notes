Recall that the sample space $S$ is the set of all possible outcomes. Then we can define a function $X: S\to\mathbb{R}$ such that $X(s)$ equals some real number $x$ for every $s\in S$. We call $X$ a **random variable**, and its **space** is the set $\set{x: X(s)=x,~s\in S}$. Since we're calling it a random variable, we typically only write $X$, but it's important to remember that we aren't referring to the mapping here but the value it would take. We can construct $X$ any way we want depending on what it is we're trying to learn about the sample space, even if $S$ already consisted of real numbers. The space of $X$ can then be thought of as the sample space and can also be denoted $S$, the **support** of $X$.

If $S$ is a one-dimensional sample space and a countable subset of the real numbers, we call it a **discrete sample space**, and any associated random variable $X$ is called a **discrete random variable**. For a random variable $X$, the probability that it takes the value $x$ is $P(X=x)$, usually denoted as $f(x)$, which is called the **probability mass function** (PMF). Just like the probability function $P$, $\sum_{x\in S}f(x)=1$, but unlike $P$, $f(x)>0$ for all $x\in S$. For any event $A$, $$P(X\in A)=\sum_{x\in A}f(x)$$where, if we remember that $X$ represents the value the function takes and not the actual function, we can see that this is a calculation for the probability that $X$ takes a value in the event $A$.

The **cumulative distribution function** (CDF, or **distribution function** of a random variable $X$) is defined by $$F(x)=P(X\leq x),~~~~-\infty<x<\infty$$and can be thought of as the sum of the PMF of all $x_i\leq x$.